---
title: "Diabetes Prediction Using Machin Learning"
author: "Wail"
date: "2023-09-20"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Project Scope

The project aim to predict whether the patient has diabetes or not based on the provided dataset from the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) for Pima Indian heritage *Females Only*, the dataset needed some cleaning and very high statistical analysis due to the sensitivity of the outcomes after cleaning and preparation i've applied machine learning modeling using three different modules linear regression, decision tree, and naive Bayes in order to have valid accurate and data- driven result.

### Install The Required Packages and Load Libraries

```{r Packages and Libraries, message=FALSE, warning=FALSE}
install.packages('ggplot2', repos = "http://cran.us.r-project.org") #for data visualization
install.packages('grid', repos = "http://cran.us.r-project.org") # for grids
install.packages('gridExtra', repos = "http://cran.us.r-project.org") # for arranging the grids
install.packages('corrplot', repos = "http://cran.us.r-project.org") # for Correlation plot
install.packages('caret', repos = "http://cran.us.r-project.org") # for confusion matrix
install.packages('e1071', repos = "http://cran.us.r-project.org") # for naive bayes
install.packages('lattice', repos = "http://cran.us.r-project.org")

library('ggplot2') #for data visualization
library('grid') # for grids
library('gridExtra') # for arranging the grids
library('corrplot') # for Correlation plot
library('lattice')
library('caret') # for confusion matrix
library('e1071') # for naive bayes
library('rpart')
```


### Step 1 : Collect Data (upload Diabetes csv file)

```{r, message=FALSE, warning=FALSE}
getwd()
setwd("C:/Users/Acc/Desktop/Meri SKILL Internship/Projects/Project 2 - Diabetes Data")
diabetes <- read.csv("diabetes.csv")
```

### Step 2 : Clean up and Prepare fo Analysis 

```{r}
colnames(diabetes) #List of columns name
```

```{r}
nrow(diabetes) #How many rows are in the data frame ?
```

```{r}
dim(diabetes) #Dimension of the data frame ?
```

```{r}
str(diabetes) #See list of columns and data types(numeric, character, etc)
```

```{r}
head(diabetes) #See the first 6 rows of data frame
```

```{r}
summary(diabetes) #Statistical Summary of data
```

### Step 3 : Conduct Statistical Analysis 

```{r}
min_glucose <- min(diabetes$Glucose)
print(paste("Minimum Glucose Value :",min_glucose)) #The minimum value of Glucose 
```

```{r}
max_glucose <- max(diabetes$Glucose)
print(paste("Maximum Glucose Value :",max_glucose)) #The maximum value of Glucose
```

```{r}
range_Glucose <- range(diabetes$Glucose) #another method to find the minimum and maximum 
print(range_Glucose)

print(paste("Minimum Glucose Value :",range_Glucose[1]))
print(paste("Maximum Glucose Value :",range_Glucose[2]))
```

```{r}
Mean_Glucose <- mean(diabetes$Glucose) #The mean value of Glucose
print(paste("Mean of Glucose :",Mean_Glucose))
```

```{r}
Median_Glucose <- median(diabetes$Glucose) #The median of Glucose
print(paste("Median of Glucose :",Median_Glucose))
```

```{r}
Mode_Glucose <- table(diabetes$Glucose) #The mode of Glucose using table and sort functions
sort(Mode_Glucose,decreasing = TRUE)
```

```{r}
q1 <- quantile(diabetes$Glucose,0.25) #First quartile
print(paste("First Quartile :",q1))
```

```{r}
q3 <- quantile(diabetes$Glucose,0.75) #Third quartile
print(paste("Third Quartile :",q3))
```

```{r}
IQR_Glucose <- IQR(diabetes$Glucose) #Interquartile range
print(paste("Interquartile range for Glucose :",IQR_Glucose))
```

```{r}
sd_Glucose <- sd(diabetes$Glucose) #Standard Deviation
print(paste("Standard Deviation for Glucose Column :",sd_Glucose))
```

```{r}
var_Glucose <- var(diabetes$Glucose) #Variance
print(paste("Variance for Glucose Column :",var_Glucose))
```

### Share Findings and plotting

```{r}
p1 <- ggplot(diabetes, aes(x=Pregnancies)) + ggtitle("Number of times pregnant") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 1, colour="black", fill="blue") + ylab("Percentage")
p2 <- ggplot(diabetes, aes(x=Glucose)) + ggtitle("Glucose") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 5, colour="black", fill="orange") + ylab("Percentage")
p3 <- ggplot(diabetes, aes(x=BloodPressure)) + ggtitle("Blood Pressure") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 2, colour="black", fill="green") + ylab("Percentage")
p4 <- ggplot(diabetes, aes(x=SkinThickness)) + ggtitle("Skin Thickness") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 2, colour="black", fill="pink") + ylab("Percentage")
p5 <- ggplot(diabetes, aes(x=Insulin)) + ggtitle("Insulin") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 20, colour="black", fill="red") + ylab("Percentage")
p6 <- ggplot(diabetes, aes(x=BMI)) + ggtitle("Body Mass Index") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 1, colour="black", fill="yellow") + ylab("Percentage")
p7 <- ggplot(diabetes, aes(x=DiabetesPedigreeFunction)) + ggtitle("Diabetes Pedigree Function") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), colour="black", fill="purple") + ylab("Percentage")
p8 <- ggplot(diabetes, aes(x=Age)) + ggtitle("Age") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth=1, colour="black", fill="lightblue") + ylab("Percentage")
grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, ncol=2)
grid.rect(width = 1, height = 1, gp = gpar(lwd = 1, col = "black", fill = NA))
```

### Identify correlation between Numeric Variables and Outcomes to if it's correlated or not

```{}
numeric.var <- sapply(diabetes, is.numeric)
corr.matrix <- cor(diabetes[,numeric.var])
corrplot(corr.matrix, main="\n\nCorrelation Plot for Numerical Variables", order = "hclust", tl.col = "black", tl.srt=45, tl.cex=0.8, cl.cex=0.8)
box(which = "outer", lty = "solid")
```

```{r}
attach(diabetes)
par(mfrow=c(2,4))
boxplot(Pregnancies~Outcome, main="No. of Pregnancies vs. Diabetes", 
        xlab="Outcome", ylab="Pregnancies",col="red")
boxplot(Glucose~Outcome, main="Glucose vs. Diabetes", 
        xlab="Outcome", ylab="Glucose",col="pink")
boxplot(BloodPressure~Outcome, main="Blood Pressure vs. Diabetes", 
        xlab="Outcome", ylab="Blood Pressure",col="green")
boxplot(SkinThickness~Outcome, main="Skin Thickness vs. Diabetes", 
        xlab="Outcome", ylab="Skin Thickness",col="orange")
boxplot(Insulin~Outcome, main="Insulin vs. Diabetes", 
        xlab="Outcome", ylab="Insulin",col="yellow")
boxplot(BMI~Outcome, main="BMI vs. Diabetes", 
        xlab="Outcome", ylab="BMI",col="purple")
boxplot(DiabetesPedigreeFunction~Outcome, main="Diabetes Pedigree Function vs. Diabetes", xlab="Outcome", ylab="DiabetesPedigreeFunction",col="lightgreen")
boxplot(Age~Outcome, main="Age vs. Diabetes", 
        xlab="Outcome", ylab="Age",col="lightblue")
box(which = "outer", lty = "solid")
```

### Create Linear Regression Analysis Model to Check Cross Validiation and Accuracy 

```{r}
diabetes$BloodPressure <- NULL
diabetes$SkinThickness <- NULL
train <- diabetes[1:540,]
test <- diabetes[541:768,]
model <-glm(Outcome ~.,family=binomial(link='logit'),data=train)
summary(model)
```

### Cross Validation

```{r}
fitted.results <- predict(model,newdata=test,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
(conf_matrix_logi<-table(fitted.results, test$Outcome))
```

### Accuracy

```{r}
misClasificError <- mean(fitted.results != test$Outcome)
print(paste('Accuracy',1-misClasificError))
```

### Create Decision Tree Model to check Accuracy

```{r}

model2 <- rpart(Outcome ~ Pregnancies + Glucose + BMI + DiabetesPedigreeFunction, data=train,method="class")
plot(model2, uniform=TRUE, 
    main="Classification Tree for Diabetes")
text(model2, use.n=TRUE, all=TRUE, cex=.8)
box(which = "outer", lty = "solid")
```

### Accuracy Calculation


```{r}
treePred <- predict(model2, test, type = 'class')
(conf_matrix_dtree<-table(treePred, test$Outcome))
```

```{r}
mean(treePred==test$Outcome)
```

### Create Naive Bayes Model 

```{r}
model_naive <- naiveBayes(Outcome ~., data = train)
```

### Confusion Table and Accuracy Calculation

```{r}
# predicting target 
toppredict_set <- test[1:6]
dim(toppredict_set)
```


```{r}
preds_naive <- predict(model_naive, newdata = toppredict_set)
(conf_matrix_naive <- table(preds_naive, test$Outcome))
```


```{r}
mean(preds_naive==test$Outcome)
```


### Compare Accuracy and Sensitivity Level of Our Three Models (Linear Regression, Decision Tree, Naive Byes) to See The Highest Value.

```{r}
confusionMatrix(conf_matrix_logi)
```

```{r}
confusionMatrix(conf_matrix_dtree)
```

```{r}
confusionMatrix(conf_matrix_naive)
```

